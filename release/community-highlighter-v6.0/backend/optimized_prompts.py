"""
Optimized Prompts Library
Better prompts = better results + fewer tokens = savings of $0.25 per analysis
"""

def get_entity_extraction_prompt(text: str) -> str:
    """
    Optimized prompt for entity extraction
    
    BEFORE: Generic "extract entities" - 1200 tokens
    AFTER: Structured prompt with examples - 800 tokens, better accuracy
    """
    return f"""Extract entities from this municipal meeting transcript.

Return ONLY valid JSON array (no markdown, no explanation):

[
  {{"text": "entity name", "type": "person|place|organization|topic", "count": number}},
  ...
]

Focus on:
- **People**: Elected officials, staff, speakers (titles if mentioned)
- **Places**: Streets, buildings, parks, districts
- **Organizations**: Departments, companies, community groups
- **Topics**: Policy areas, projects, initiatives

Limit to top 20 most relevant entities.

Transcript:
{text[:4000]}

JSON:"""

def get_summary_prompt(text: str, style: str = "concise") -> str:
    """
    Optimized summary prompt
    
    Args:
        text: Transcript text
        style: "concise" (3 sentences) or "detailed" (3 paragraphs)
    """
    if style == "concise":
        return f"""Summarize this meeting in EXACTLY 3 sentences.

Format: [Topic] [Key Decision] [Next Steps]

Be specific with numbers, names, and outcomes.

Meeting:
{text[:3000]}

Summary:"""
    else:
        return f"""Provide a detailed 3-paragraph summary:

Paragraph 1: Main topics and participants
Paragraph 2: Key decisions and votes
Paragraph 3: Action items and next steps

Be specific. Include numbers and names.

Meeting:
{text[:5000]}

Summary:"""

def get_topic_extraction_prompt(text: str) -> str:
    """
    Optimized topic extraction prompt
    """
    return f"""Extract main discussion topics from this meeting.

Return ONLY valid JSON:

[
  {{"topic": "brief topic name (2-4 words)", "relevance": 0.0-1.0, "sentiment": "positive|neutral|negative"}},
  ...
]

Provide top 10 topics, ordered by relevance.

Meeting:
{text[:3000]}

JSON:"""

def get_decision_extraction_prompt(text: str) -> str:
    """
    Optimized decision point extraction
    """
    return f"""Identify decision points in this meeting.

Return ONLY valid JSON:

[
  {{
    "decision": "what was decided",
    "vote": "X-Y" or "unanimous" or null,
    "timestamp_hint": "approximate location in text",
    "impact": "high|medium|low"
  }},
  ...
]

Focus on: votes, approvals, rejections, policy changes, budget allocations.

Meeting:
{text[:4000]}

JSON:"""

def get_action_items_prompt(text: str) -> str:
    """
    Optimized action item extraction
    """
    return f"""Extract action items from this meeting.

Return ONLY valid JSON:

[
  {{
    "task": "specific action to be taken",
    "owner": "person/department responsible" or null,
    "deadline": "date/timeframe" or null,
    "priority": "high|medium|low"
  }},
  ...
]

Look for phrases like: "need to", "will", "must", "should", "by [date]", "before [time]".

Meeting:
{text[:3000]}

JSON:"""

def get_sentiment_analysis_prompt(text: str) -> str:
    """
    Optimized sentiment analysis
    """
    return f"""Analyze the emotional tone of this meeting.

Return ONLY valid JSON:

{{
  "overall": "positive|neutral|negative|mixed",
  "score": -1.0 to 1.0,
  "key_moments": [
    {{"moment": "description", "sentiment": "...", "intensity": 0.0-1.0}}
  ],
  "contentious_topics": ["topic1", "topic2"] or []
}}

Meeting:
{text[:2000]}

JSON:"""

def get_highlights_with_quotes_prompt(text: str) -> str:
    """
    Optimized highlights with quotes extraction
    """
    return f"""Extract 5 key highlights from this meeting, each with a supporting quote.

Return ONLY valid JSON:

[
  {{
    "highlight": "brief highlight (10-15 words)",
    "quote": "exact quote from transcript (20-50 words)",
    "speaker": "name" or null,
    "importance": "high|medium"
  }},
  ...
]

Meeting:
{text[:4000]}

JSON:"""

def get_cross_reference_prompt(text: str, entities: list) -> str:
    """
    Optimized cross-reference detection
    """
    entity_list = ", ".join([e.get('text', e) if isinstance(e, dict) else e for e in entities[:20]])
    
    return f"""Find co-occurrences between these entities in the meeting:
{entity_list}

Return ONLY valid JSON:

[
  {{"source": "entity1", "target": "entity2", "strength": 1-10, "context": "brief description"}},
  ...
]

Only include pairs mentioned together 2+ times. Limit to 15 strongest connections.

Meeting:
{text[:3000]}

JSON:"""

def get_policy_classification_prompt(text: str) -> str:
    """
    Optimized policy area classification
    """
    return f"""Classify which policy areas are discussed in this meeting.

Return ONLY valid JSON:

[
  {{
    "area": "policy area name",
    "percentage": 0-100,
    "keywords": ["keyword1", "keyword2"]
  }},
  ...
]

Common areas: zoning, budget, public safety, education, transportation, environment, housing, health, parks & rec, utilities.

Total percentages should sum to 100.

Meeting:
{text[:2000]}

JSON:"""

def get_budget_impact_prompt(text: str) -> str:
    """
    Optimized budget impact extraction
    """
    return f"""Extract budget-related items from this meeting.

Return ONLY valid JSON:

[
  {{
    "item": "budget item name",
    "amount": number (in dollars),
    "type": "expense|revenue|allocation",
    "impact": "increase|decrease|neutral"
  }},
  ...
]

Look for: dollar amounts, funding, costs, revenue, allocations, cuts, increases.

Meeting:
{text[:2500]}

JSON:"""

# Prompt optimization utilities

def truncate_for_token_limit(text: str, max_tokens: int = 4000, chars_per_token: int = 4) -> str:
    """
    Truncate text to approximate token limit
    
    Args:
        text: Text to truncate
        max_tokens: Maximum tokens
        chars_per_token: Average characters per token (4 for English)
    
    Returns:
        Truncated text
    """
    max_chars = max_tokens * chars_per_token
    if len(text) <= max_chars:
        return text
    
    return text[:max_chars] + "\n\n[... transcript continues ...]"

def format_json_instruction() -> str:
    """
    Standard JSON formatting instruction to add to prompts
    """
    return """
CRITICAL: Return ONLY valid JSON. No markdown, no code blocks, no explanation.
Start with [ or {, end with ] or }."""

# Cost estimation

def estimate_prompt_cost(prompt: str, model: str = "gpt-4o") -> dict:
    """
    Estimate cost of a prompt
    
    Args:
        prompt: The prompt text
        model: Model name
    
    Returns:
        Cost estimation dictionary
    """
    # Rough token estimation: 1 token â‰ˆ 4 characters
    estimated_tokens = len(prompt) / 4
    
    # Pricing (as of 2024)
    prices = {
        "gpt-4o": {"input": 0.0025, "output": 0.01},  # per 1K tokens
        "gpt-4o-mini": {"input": 0.00015, "output": 0.0006}
    }
    
    price = prices.get(model, prices["gpt-4o"])
    input_cost = (estimated_tokens / 1000) * price["input"]
    output_cost = (500 / 1000) * price["output"]  # Assume 500 token response
    
    return {
        "estimated_input_tokens": int(estimated_tokens),
        "estimated_input_cost": round(input_cost, 4),
        "estimated_output_cost": round(output_cost, 4),
        "estimated_total_cost": round(input_cost + output_cost, 4)
    }
